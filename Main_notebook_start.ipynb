{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chimera Movie Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new movie streaming service 'Cinemania' is looking for a way to increase movie streams. They have asked Chimera Solutions to provide the means of connecting subscribers to movies that they will enjoy, and then link to them to other movies that they will enjoy. The goal of this notebook is to construct a recommendation system that will accurately link subscribers to movies that fit their unique tastes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cinemania is trying to enter the highly saturated streaming service field, and is looking for the means to level the playing field. They need a recommendation system that is accurate enough to give users a reason to use their service over the many other ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Stakeholder:__ Cinemania\n",
    "\n",
    "\n",
    "- __Significance of Recommendations:__ Recommendations need to be accurate so that users keep watching more and more movies on the stakeholder's streaming service\n",
    "\n",
    "\n",
    "- __Deliverable:__ An interpretable Recommendation Model that the stakeholder can easily understand\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD, SVDpp, NMF, NormalPredictor, KNNBaseline, KNNBasic,\\\n",
    "KNNWithMeans, KNNWithZScore, BaselineOnly, CoClustering, SlopeOne\n",
    "\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise.model_selection import train_test_split as sur_tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('data/movies.csv')\n",
    "ratings = pd.read_csv('data/ratings.csv')\n",
    "links = pd.read_csv('data/links.csv')\n",
    "tags = pd.read_csv('data/tags.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movies Dataset Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(movies.shape)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! no missing values in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies['movieId'].nunique())\n",
    "print(movies['title'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 duplicated Movie titles, but that is not a big deal for what we are trying to accomplish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratings Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(ratings.shape)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values in our ratings datset, duplicates are expected here because one user can rate multiple movies, and a movie can be rated by multiple users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['rating'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a slightly skewed distribution of ratings, but this is just how users rated their movies, so this will be left as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = ratings['userId'].nunique()\n",
    "movie = ratings['movieId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {users} rating {movie} movies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have way more movies than users which is to be expected with a new streaming service. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tags Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tags.shape)\n",
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values and the tag column is just a user generated phrase describing something that stood out to them in the movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is not really important for our recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Links Dataset Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(links.shape)\n",
    "links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Further research into this dataset, we found that these were Id numbers that provide links to the actual movies on imdb and The Movie Database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is not needed for our recommendation system, we want users to watch movies on Cinemania's Streaming Service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data for our recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the __ratings__ dataset to produce recommendations to users based on what similar users have rated highly, and we are going to use the title and genre columns from the __movies__ dataset to make the output of of our model more interpretable by using the title rather than the movieId. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the high number of movies with only a few reviews (<=10), we decided to remove those ratings so our model would provide more accurate and confident recommendations. This results in a reduction of 20,000 ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100836\n",
      "79636\n"
     ]
    }
   ],
   "source": [
    "print(len(ratings.index))\n",
    "unique_movies = ratings['movieId'].unique()\n",
    "\n",
    "movie_count = {}\n",
    "\n",
    "for i in unique_movies:\n",
    "    movie_count[i]= 0\n",
    "    \n",
    "for i in ratings['movieId']:\n",
    "    movie_count[i] += 1\n",
    "\n",
    "rare_movies = []\n",
    "for movie in movie_count.keys():\n",
    "    if movie_count[movie] <= 10:\n",
    "        rare_movies.append(movie)\n",
    "        \n",
    "to_delete = []\n",
    "for index, row in ratings.iterrows():\n",
    "    if row.movieId in rare_movies:\n",
    "        to_delete.append(index)\n",
    "        \n",
    "ratings.drop(to_delete,inplace=True)\n",
    "print(len(ratings.index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Different Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data = ratings.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(line_format='user item rating', sep=',')\n",
    "data = Dataset.load_from_df(rating_data, reader=reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remember to Remove this markdown before submission__ This cell takes a very long time to run, this is just a note for us when going through the notebook. __do not have to run this cell__ just look at output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "for algorithm in [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]:\n",
    "    # Perform cross validation to see which algorithms give lowest RMSE\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    \n",
    "    # Create a dataframe with the algorithm as the index\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVDpp, BaselineOnly, SVD, and KNNBaseline are our top 4 models with default parameeters. \n",
    "- SVDpp is only a point better but is way more computationally expensive than the other 3 seeing that it took a total of 419 seconds(7 minutes) to fit and test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split our data into a Training and Testset and train the best performing models on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use sklearn library train test split\n",
    "y = pd.DataFrame(rating_data['rating'])\n",
    "X= rating_data.drop('rating',axis=1)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "#remerge to convert using reader\n",
    "\n",
    "train_df = pd.concat([X_train,y_train],axis=1)\n",
    "\n",
    "test_df = pd.concat([X_test,y_test],axis=1)\n",
    "\n",
    "#convert to surprise dataframes\n",
    "trainset= Dataset.load_from_df(train_df, reader=reader)\n",
    "\n",
    "testset = Dataset.load_from_df(test_df, reader=reader)\n",
    "\n",
    "#make testset data usable for testing\n",
    "\n",
    "blank,testset = sur_tts(testset, test_size=.95)\n",
    "\n",
    "type(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_factors': 250, 'n_epochs': 40, 'lr_all': 0.025, 'reg_all': 0.06}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a gridsearch to find best params for SVD\n",
    "param_grid = {'n_factors':[50,200,250],'n_epochs':[25,30,40],\n",
    "              'lr_all':[.025,.05,.075],'reg_all':[.04,.05,.06]}\n",
    "\n",
    "gs_svd = GridSearchCV(SVD,param_grid,measures=['rmse'],cv=3,n_jobs=-1)\n",
    "gs_svd.fit(trainset)\n",
    "\n",
    "params = gs_svd.best_params['rmse']\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8353588248946192"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test best SVD on testset\n",
    "\n",
    "algo = SVD(n_factors= 250, n_epochs=40, lr_all= 0.025, reg_all= 0.06)\n",
    "\n",
    "train_set = trainset.build_full_trainset()\n",
    "algo.fit(train_set)\n",
    "\n",
    "preds = algo.test(testset)\n",
    "\n",
    "accuracy.rmse(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.6374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6373621355575251"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mae(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
